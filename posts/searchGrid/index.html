
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Tuning Algorithm for XGBoost &#8212;   documentation</title>
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/alabaster.css" />
    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="author" title="About these documents" href="../../about/" />
    <link rel="index" title="Index" href="../../genindex/" />
    <link rel="search" title="Search" href="../../search/" /> 
   
  <link rel="stylesheet" href="../../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />
  
<style type="text/css">
  ul.ablog-archive {
    list-style: none;
    overflow: auto;
    margin-left: 0px;
  }
  ul.ablog-archive li {
    float: left;
    margin-right: 5px;
    font-size: 80%;
  }
  ul.postlist a {
    font-style: italic;
  }
  ul.postlist-style-disc {
    list-style-type: disc;
  }
  ul.postlist-style-none {
    list-style-type: none;
  }
  ul.postlist-style-circle {
    list-style-type: circle;
  }
</style>

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
             <section id="tuning-algorithm-for-xgboost">
<h1>Tuning Algorithm for XGBoost<a class="headerlink" href="#tuning-algorithm-for-xgboost" title="Permalink to this heading">¶</a></h1>
<p>My earlier post on XGBoost in Python got me interested in writing my
own tuning algorithm. I wanted to tune the XGBoost algorithm on a
reasonably large parameter grid but was put off by the time it would
take. Although, using scikit-learn’s RandomizedSearchCV would speed
things up I wanted to do a slightly more thorough search. So I decided
to use the idea of a random search but to also go one step further by
searching in the neighbourhood of the best random parameter to optimise
the result.</p>
<p>This post is going to be a lot of code. Although I’ve tailored it to an
XGBoost model for a binary classification problem it could be easily
adapted to other modelling problems. Also, extra parameters could be
added to the algorithm if need be. One of the biggest challenges in
writing the algorithm was indexing correctly and accessing values in
dictionaries. The example grid I will present here has 4 parameters to
tune on and a total of 35 individual parameter values. I we had run a
grid search on the entire grid then 5400 parameter combinations would
have had to have been tested, with my algoirthm I test up to 91
combinations in the best neighbourhood after testing n different random
values.</p>
<p>As usual, start by importing the relevant libraries. In this block of
code, I’ve also blocked a particular warning which is a bug in sklearn
related to the use of LabelEncoder. This is a known error and has been
fixed in later versions. I’m using sklearn version 0.19.1 with Numpy
1.14.0.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">#Import the libraries</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">OneHotEncoder</span><span class="p">,</span> <span class="n">LabelBinarizer</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">import</span> <span class="nn">xgboost</span> <span class="k">as</span> <span class="nn">xgb</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">roc_auc_score</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">copy</span>
<span class="kn">from</span> <span class="nn">itertools</span> <span class="kn">import</span> <span class="n">product</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">datetime</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="n">module</span><span class="o">=</span><span class="s1">&#39;sklearn*&#39;</span><span class="p">,</span> <span class="n">action</span><span class="o">=</span><span class="s1">&#39;ignore&#39;</span><span class="p">,</span>
                                                <span class="n">category</span><span class="o">=</span><span class="ne">DeprecationWarning</span><span class="p">)</span>
</pre></div>
</div>
<p>The grid search is broken up into 3 functions. This first function
randomly generates a set of parameters from the grid to be searched. The
grid needs to be in dictionary format. The output is a random candidate
and the corresponding indices. The indices are used as input to the
following function, it saves having to identify them again later.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">generate_candidate</span><span class="p">(</span><span class="n">grid</span><span class="p">):</span>

    <span class="n">k</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="n">grid</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span> <span class="c1">#get the dictionary keys from the grid</span>
    <span class="n">n_vars</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">k</span><span class="p">)</span> <span class="c1">#get the number of parameters</span>

    <span class="c1">#Create an empty combination of parameters by copying the</span>
    <span class="c1">#grid and setting each list of parameter values to 0</span>
    <span class="n">candidate</span><span class="o">=</span><span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">grid</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_vars</span><span class="p">):</span>
        <span class="n">candidate</span><span class="p">[</span><span class="n">k</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span><span class="o">=</span><span class="mi">0</span>
    <span class="n">candidate</span><span class="o">=</span><span class="p">[</span><span class="n">candidate</span><span class="p">]</span> <span class="c1">#convert to list for indexing</span>

    <span class="c1">#Initialise a randomly generated set of parameter positions</span>
    <span class="n">indices</span><span class="o">=</span><span class="p">[]</span>
    <span class="n">els</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">grid</span><span class="o">.</span><span class="n">items</span><span class="p">())</span> <span class="c1">#convert dictionary to list for indexing</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">els</span><span class="p">)):</span>
        <span class="c1">#generate random indices</span>
        <span class="n">indices</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">els</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">])</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>

    <span class="c1">#Attribute parameter values to the parameter labels using the random indices</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_vars</span><span class="p">):</span>
        <span class="n">candidate</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">k</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span> <span class="o">=</span> <span class="n">grid</span><span class="p">[</span><span class="n">k</span><span class="p">[</span><span class="n">i</span><span class="p">]][</span><span class="n">indices</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span>

    <span class="k">return</span> <span class="n">candidate</span><span class="p">,</span> <span class="n">indices</span>
</pre></div>
</div>
<p>This next function generates a list of all the parameters in the
neighbourhood of <span class="math notranslate nohighlight">\(s0\)</span> where <span class="math notranslate nohighlight">\(s0\)</span> is a list of indices for each parameter
value of a candidate (the output “indices” from above). The values
considered in the neighbourhood are all the combinations of <span class="math notranslate nohighlight">\(\{s0, s0-1,
s0+1\}\)</span>.</p>
<p>For example; if we have:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">grid</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;min_child_weight&#39;</span><span class="p">:[</span><span class="mi">10</span><span class="p">,</span><span class="mi">15</span><span class="p">,</span><span class="mi">20</span><span class="p">,</span><span class="mi">30</span><span class="p">,</span><span class="mi">40</span><span class="p">],</span>
        <span class="s1">&#39;max_depth&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">20</span><span class="p">],</span>
        <span class="s1">&#39;n_estimators&#39;</span><span class="p">:[</span><span class="mi">100</span><span class="p">,</span><span class="mi">200</span><span class="p">,</span><span class="mi">300</span><span class="p">,</span><span class="mi">400</span><span class="p">]}</span>
</pre></div>
</div>
<p>for s0=[3,3,3], then the neighbourhood will take all combinations of :
{‘min_child_weight’:[15,20,30], ‘max_depth’: [5,10,20] ,
‘n_estimators’:[200,300,400]}.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">generate_neighbourhood</span><span class="p">(</span><span class="n">grid</span><span class="p">,</span><span class="n">s0</span><span class="p">):</span>

    <span class="n">k</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="n">grid</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span> <span class="c1">#get the dictionary keys</span>
    <span class="n">n_vars</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">k</span><span class="p">)</span> <span class="c1">#get the number of parameters</span>
    <span class="c1">#generate relative indices combinations</span>
    <span class="n">mvts</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">product</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">repeat</span><span class="o">=</span><span class="n">n_vars</span><span class="p">)</span> <span class="p">)</span>

    <span class="c1">#Generate the list of combinations of indices</span>
    <span class="n">comb</span><span class="o">=</span><span class="nb">list</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">mvts</span><span class="p">)):</span>
        <span class="n">comb</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">mvts</span><span class="p">[</span><span class="n">i</span><span class="p">])</span><span class="o">+</span><span class="n">s0</span><span class="p">))</span>

    <span class="c1">#Generate the list of combinations containing at least one value outside</span>
    <span class="c1">#of parameter indice ranges</span>
    <span class="n">l</span><span class="o">=</span><span class="p">[]</span> <span class="c1">#intialise the list</span>
    <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">comb</span><span class="p">)):</span>
        <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_vars</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">comb</span><span class="p">[</span><span class="n">c</span><span class="p">][</span><span class="n">n</span><span class="p">]</span> <span class="o">&lt;</span><span class="mi">0</span> <span class="ow">or</span> <span class="n">comb</span><span class="p">[</span><span class="n">c</span><span class="p">][</span><span class="n">n</span><span class="p">]</span> <span class="o">&gt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">grid</span><span class="p">[</span><span class="n">k</span><span class="p">[</span><span class="n">n</span><span class="p">]])</span><span class="o">-</span><span class="mi">1</span> <span class="p">:</span>
                <span class="n">l</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">c</span><span class="p">)</span>

    <span class="c1">#Remove the combinations containing at least one out-of-range index</span>
    <span class="n">comb</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">comb</span><span class="p">)</span> <span class="k">if</span> <span class="n">j</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">l</span><span class="p">]</span>

    <span class="c1">#Create an empty combination of parameters by copying the grid</span>
    <span class="c1">#and setting each list of parameter values to 0</span>
    <span class="n">neighbours</span><span class="o">=</span><span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">grid</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_vars</span><span class="p">):</span>
        <span class="n">neighbours</span><span class="p">[</span><span class="n">k</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span><span class="o">=</span><span class="mi">0</span>
    <span class="n">neighbours</span><span class="o">=</span><span class="p">[</span><span class="n">neighbours</span><span class="p">]</span><span class="c1">#convert to list for indexing</span>

    <span class="c1">#Create a list of i empty parameters sets corresponding to the number</span>
    <span class="c1">#of combinations</span>
    <span class="n">n</span><span class="o">=</span><span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">neighbours</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">comb</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">neighbours</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">n</span><span class="p">))</span>

    <span class="c1">#Attribute the values to the parameter labels</span>
    <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">comb</span><span class="p">)):</span> <span class="c1">#for each combination</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_vars</span><span class="p">):</span> <span class="c1">#for each label in a given combination</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">grid</span><span class="p">[</span><span class="n">k</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span> <span class="c1">#test that grid value exists</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="c1">#assign the parameter values</span>
                    <span class="n">neighbours</span><span class="p">[</span><span class="n">m</span><span class="p">][</span><span class="n">k</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span>
                    <span class="n">neighbours</span><span class="p">[</span><span class="n">m</span><span class="p">][</span><span class="n">k</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span> <span class="o">=</span> <span class="n">grid</span><span class="p">[</span><span class="n">k</span><span class="p">[</span><span class="n">i</span><span class="p">]][</span><span class="n">comb</span><span class="p">[</span><span class="n">m</span><span class="p">][</span><span class="n">i</span><span class="p">]]</span>
                <span class="k">except</span><span class="p">:</span>
                    <span class="k">pass</span>
            <span class="k">except</span><span class="p">:</span>
                <span class="k">del</span> <span class="n">neighbours</span><span class="p">[</span><span class="n">m</span><span class="p">]</span>
                <span class="k">pass</span>

    <span class="k">return</span> <span class="n">neighbours</span>
</pre></div>
</div>
<div class="line-block">
<div class="line">Finally we define the function which carries out the grid search. With
the following parameters:</div>
<div class="line"><em>grid</em> - grid to be searched</div>
<div class="line"><em>data</em> - data to be modeled</div>
<div class="line"><em>y loc</em> - column holding the y variable to be predicted</div>
<div class="line"><em>n hood</em> - number of random candidates to be tested before searching
thoroughly in the best neighbourhood</div>
<div class="line"><em>cv</em> - the number of cross-validation folds</div>
<div class="line"><em>balance</em> - if True duplicates of the positive observations will be
made</div>
<div class="line"><em>early stopping rounds</em> - the XGBoost parameter of the same name (so
you can speed things up)</div>
<div class="line"><em>r</em> - ratio of data in the training dataset</div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">gridSearch</span><span class="p">(</span><span class="n">grid</span><span class="p">,</span> <span class="n">df</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">n_hoods</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">balance</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
               <span class="n">early_stopping_rounds</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span><span class="n">r</span><span class="o">=</span><span class="mf">0.8</span><span class="p">):</span>

    <span class="n">start</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>

    <span class="c1">#Create the cross-validation datasets.</span>
    <span class="n">datasets</span><span class="o">=</span><span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">cv</span><span class="p">):</span>
        <span class="n">train</span><span class="p">,</span> <span class="n">test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">train_size</span><span class="o">=</span><span class="n">r</span><span class="p">,</span>
                        <span class="n">test_size</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">r</span><span class="p">),</span> <span class="n">stratify</span><span class="o">=</span><span class="n">df</span><span class="p">[</span><span class="n">target</span><span class="p">]</span> <span class="p">)</span>

        <span class="c1">#encode independant variables</span>
        <span class="n">enc</span> <span class="o">=</span> <span class="n">OneHotEncoder</span><span class="p">(</span><span class="n">handle_unknown</span> <span class="o">=</span> <span class="s1">&#39;ignore&#39;</span><span class="p">)</span>
        <span class="n">enc</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="n">target</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">X_train</span> <span class="o">=</span> <span class="n">enc</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">train</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="n">target</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">X_test</span> <span class="o">=</span> <span class="n">enc</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">test</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="n">target</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>

        <span class="c1">#encode target</span>
        <span class="n">lb</span> <span class="o">=</span> <span class="n">LabelBinarizer</span><span class="p">()</span>
        <span class="n">lb</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="n">target</span><span class="p">])</span>
        <span class="n">y_train</span> <span class="o">=</span> <span class="n">lb</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="n">target</span><span class="p">])</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
        <span class="n">y_test</span> <span class="o">=</span> <span class="n">lb</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">test</span><span class="p">[</span><span class="n">target</span><span class="p">])</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>

        <span class="n">datasets</span><span class="o">.</span><span class="n">append</span><span class="p">([[</span><span class="n">X_train</span><span class="p">],[</span><span class="n">y_train</span><span class="p">],[</span><span class="n">X_test</span><span class="p">],[</span><span class="n">y_test</span><span class="p">]])</span>


    <span class="c1">#Initialise the parameters</span>
    <span class="n">params</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;objective&#39;</span><span class="p">:</span><span class="s1">&#39;binary:logistic&#39;</span><span class="p">,</span> <span class="s1">&#39;eval_metric&#39;</span> <span class="p">:</span> <span class="s1">&#39;auc&#39;</span><span class="p">,</span><span class="s1">&#39;nthread&#39;</span><span class="p">:</span><span class="mi">4</span><span class="p">,</span>
              <span class="s1">&#39;early_stopping_rounds&#39;</span> <span class="p">:</span> <span class="n">early_stopping_rounds</span><span class="p">}</span>

    <span class="c1">#Initialise the variables</span>
    <span class="n">metric_bestCandidate</span><span class="o">=</span><span class="mi">0</span>
    <span class="n">tabuList</span><span class="o">=</span><span class="p">[]</span> <span class="c1">#this list is used to identify candidates that have already been tested</span>
    <span class="n">n</span><span class="o">=</span><span class="mi">0</span> <span class="c1">#used to count the number of random parameter sets tested</span>

    <span class="k">while</span> <span class="p">(</span><span class="n">metric_bestCandidate</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">):</span>

        <span class="k">while</span> <span class="n">n</span><span class="o">&lt;</span><span class="n">n_hoods</span><span class="p">:</span>
            <span class="n">n</span><span class="o">=</span><span class="n">n</span><span class="o">+</span><span class="mi">1</span>
            <span class="n">candidate</span><span class="p">,</span> <span class="n">indices</span> <span class="o">=</span><span class="n">generate_candidate</span><span class="p">(</span><span class="n">grid</span><span class="p">)</span> <span class="c1">#generate a random candidate</span>

            <span class="k">if</span> <span class="p">[</span><span class="nb">list</span><span class="p">(</span><span class="n">candidate</span><span class="p">)[</span><span class="mi">0</span><span class="p">]]</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">tabuList</span><span class="p">:</span> <span class="c1">#if the candidate hasn&#39;t been tested already</span>
                <span class="n">tabuList</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">candidate</span><span class="p">))</span>
                <span class="n">metric_total</span><span class="o">=</span><span class="mi">0</span>

                <span class="c1">#For each pre-defined dataset, test the parameter set on the data and calulate the average metric</span>
                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">cv</span><span class="p">):</span>
                    <span class="n">X_train</span> <span class="o">=</span> <span class="n">datasets</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
                    <span class="n">y_train</span> <span class="o">=</span> <span class="n">datasets</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
                    <span class="n">X_test</span>  <span class="o">=</span> <span class="n">datasets</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">2</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
                    <span class="n">y_test</span>  <span class="o">=</span> <span class="n">datasets</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">3</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>

                    <span class="n">params</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">candidate</span><span class="p">)[</span><span class="mi">0</span><span class="p">])</span> <span class="c1">#update the parameters</span>

                    <span class="k">if</span> <span class="n">balance</span><span class="o">==</span><span class="kc">True</span><span class="p">:</span>
                        <span class="n">w</span><span class="o">=</span><span class="nb">round</span><span class="p">(</span><span class="n">y_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">/</span><span class="nb">sum</span><span class="p">(</span><span class="n">y_train</span><span class="p">),</span><span class="mi">2</span><span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">w</span><span class="o">=</span><span class="mi">1</span>

                    <span class="n">xgb_model</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">XGBClassifier</span><span class="p">(</span><span class="o">**</span><span class="n">params</span><span class="p">,</span> <span class="n">verbosity</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span><span class="n">scale_pos_weight</span> <span class="o">=</span> <span class="n">w</span><span class="p">)</span> <span class="c1">#update the model</span>
                    <span class="n">xgb_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span> <span class="c1">#train the model</span>
                    <span class="n">pred</span><span class="o">=</span><span class="n">xgb_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span> <span class="c1">#prediction on the test dataset</span>
                    <span class="n">metric_candidate</span> <span class="o">=</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="n">pred</span><span class="p">)</span> <span class="c1">#quality of the test dataset</span>

                    <span class="n">metric_total</span><span class="o">=</span><span class="n">metric_total</span><span class="o">+</span><span class="n">metric_candidate</span> <span class="c1">#sum the metric values</span>

                <span class="n">metric_mean</span><span class="o">=</span><span class="n">metric_total</span><span class="o">/</span><span class="n">cv</span><span class="c1">#calculate the average metric value</span>

                <span class="c1">#If the candidate tested gives a better result then the previous best, then update the best</span>
                <span class="c1">#candidate and the best metric value</span>
                <span class="k">if</span> <span class="n">metric_mean</span> <span class="o">&gt;</span> <span class="n">metric_bestCandidate</span><span class="p">:</span>
                    <span class="n">bestCandidate</span> <span class="o">=</span> <span class="n">candidate</span>
                    <span class="n">metric_bestCandidate</span><span class="o">=</span><span class="n">metric_candidate</span>
                    <span class="n">bestCandidateIndices</span><span class="o">=</span><span class="n">indices</span> <span class="c1">#used to generate the neighbourhood in the next step</span>
                    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;**new best** &#39;</span><span class="p">,</span><span class="s1">&#39;candidate: &#39;</span><span class="p">,</span> <span class="nb">list</span><span class="p">(</span><span class="n">candidate</span><span class="p">)[</span><span class="mi">0</span><span class="p">],</span> <span class="s1">&#39;mean metric&#39;</span><span class="p">,</span> <span class="nb">round</span><span class="p">(</span><span class="n">metric_mean</span><span class="p">,</span><span class="mi">4</span><span class="p">)</span> <span class="p">)</span> <span class="c1">#print update</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;candidate: &#39;</span><span class="p">,</span> <span class="nb">list</span><span class="p">(</span><span class="n">candidate</span><span class="p">)[</span><span class="mi">0</span><span class="p">],</span> <span class="s1">&#39;mean metric&#39;</span><span class="p">,</span> <span class="nb">round</span><span class="p">(</span><span class="n">metric_mean</span><span class="p">,</span><span class="mi">4</span><span class="p">)</span> <span class="p">)</span> <span class="c1">#print update</span>

        <span class="c1">#Once n_hood candidates have been tested. Generate the list of neighbours of the best candidate</span>
        <span class="n">neighbourhood</span><span class="o">=</span><span class="n">generate_neighbourhood</span><span class="p">(</span><span class="n">grid</span><span class="p">,</span> <span class="n">bestCandidateIndices</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;TEST NEIGHBOURHOOD OF BEST CANDIDATE:&#39;</span><span class="p">,</span> <span class="nb">list</span><span class="p">(</span><span class="n">bestCandidate</span><span class="p">))</span>

        <span class="n">i</span><span class="o">=</span><span class="mi">0</span> <span class="c1">#count the number of candidates tested in the neighbourhood</span>

        <span class="c1">#Test the candidates in the neighbourhood</span>
        <span class="k">for</span> <span class="n">candidate</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">neighbourhood</span><span class="p">):</span>
            <span class="k">if</span> <span class="p">[</span><span class="nb">list</span><span class="p">(</span><span class="n">candidate</span><span class="p">)[</span><span class="mi">1</span><span class="p">]]</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">tabuList</span><span class="p">:</span> <span class="c1">#if the candidate has been tested already then do nothing</span>
                <span class="n">metric_total</span><span class="o">=</span><span class="mi">0</span>
                <span class="n">i</span><span class="o">=</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span>

                <span class="c1">#For each pre-defined dataset, test the parameter set on the data and calulate the average metric</span>
                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">cv</span><span class="p">):</span>
                    <span class="n">X_train</span> <span class="o">=</span> <span class="n">datasets</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
                    <span class="n">y_train</span> <span class="o">=</span> <span class="n">datasets</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
                    <span class="n">X_test</span>  <span class="o">=</span> <span class="n">datasets</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">2</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
                    <span class="n">y_test</span>  <span class="o">=</span> <span class="n">datasets</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">3</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>

                    <span class="n">params</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">candidate</span><span class="p">)[</span><span class="mi">1</span><span class="p">])</span> <span class="c1">#update the parameters</span>

                    <span class="k">if</span> <span class="n">balance</span><span class="o">==</span><span class="kc">True</span><span class="p">:</span>
                        <span class="n">w</span><span class="o">=</span><span class="nb">round</span><span class="p">(</span><span class="n">y_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">/</span><span class="nb">sum</span><span class="p">(</span><span class="n">y_train</span><span class="p">),</span><span class="mi">2</span><span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">w</span><span class="o">=</span><span class="mi">1</span>
                    <span class="n">xgb_model</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">XGBClassifier</span><span class="p">(</span><span class="o">**</span><span class="n">params</span><span class="p">,</span> <span class="n">verbosity</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">scale_pos_weight</span> <span class="o">=</span> <span class="n">w</span><span class="p">)</span> <span class="c1">#update the model</span>
                    <span class="n">xgb_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span> <span class="c1">#train the model</span>
                    <span class="n">pred</span><span class="o">=</span><span class="n">xgb_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span> <span class="c1">#prediction on the test dataset</span>
                    <span class="n">metric_candidate</span> <span class="o">=</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="n">pred</span> <span class="p">)</span> <span class="c1">#quality of the test dataset</span>

                    <span class="n">metric_total</span><span class="o">=</span><span class="n">metric_total</span><span class="o">+</span><span class="n">metric_candidate</span>

                <span class="n">metric_mean</span><span class="o">=</span><span class="n">metric_total</span><span class="o">/</span><span class="n">cv</span>

                <span class="c1">#If the candidate tested gives a better result then the previous best, then update the best</span>
                <span class="c1">#candidate and the best metric value</span>
                <span class="k">if</span> <span class="n">metric_mean</span> <span class="o">&gt;</span> <span class="n">metric_bestCandidate</span><span class="p">:</span>
                    <span class="n">bestCandidate</span> <span class="o">=</span> <span class="n">candidate</span>
                    <span class="n">metric_bestCandidate</span><span class="o">=</span><span class="n">metric_mean</span>
                    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;**new best** &#39;</span><span class="p">,</span><span class="s1">&#39;candidate: &#39;</span><span class="p">,</span> <span class="nb">list</span><span class="p">(</span><span class="n">candidate</span><span class="p">)[</span><span class="mi">1</span><span class="p">],</span> <span class="s1">&#39;mean metric&#39;</span><span class="p">,</span> <span class="nb">round</span><span class="p">(</span><span class="n">metric_mean</span><span class="p">,</span><span class="mi">4</span><span class="p">)</span> <span class="p">)</span> <span class="c1">#print update</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;candidate: &#39;</span><span class="p">,</span> <span class="nb">list</span><span class="p">(</span><span class="n">candidate</span><span class="p">)[</span><span class="mi">1</span><span class="p">],</span> <span class="s1">&#39;mean metric&#39;</span><span class="p">,</span> <span class="nb">round</span><span class="p">(</span><span class="n">metric_mean</span><span class="p">,</span><span class="mi">4</span><span class="p">)</span> <span class="p">)</span> <span class="c1">#print update</span>

        <span class="k">if</span> <span class="n">i</span><span class="o">==</span><span class="mi">0</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;no additional candidates tested&#39;</span><span class="p">)</span> <span class="c1">#print update</span>

        <span class="k">break</span>

    <span class="nb">print</span><span class="p">(</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span> <span class="o">-</span> <span class="n">start</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">bestCandidate</span><span class="p">,</span> <span class="n">metric_bestCandidate</span>
</pre></div>
</div>
<p>I tested my grid search on the dataset from the <a class="reference external" href="https://archive.ics.uci.edu/ml/datasets/Bank%2BMarketing">UCI Machine Learning
Repository</a>
that I previously used for my post on XGBoost. The next block of code
imports and processes this data.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">#Import the dataset</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;C:/..../bank-full.csv&#39;</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="s2">&quot;;&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>I ran a couple of iterations on the data set. Due to the first random
step, I didn’t get the same results and I think it would be well worth
increasing the number of random candidates tested - I only tested 10.</p>
<p>My grid below has 5400 possible parameter combinations, but I’ll test a
maximum of 91. Note that some of the values in the below grid have been
chosen to reduce running time during testing. For example, most of the
choices for the number of estimators are low.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">#Initialise search grid</span>
<span class="n">grid</span> <span class="o">=</span> <span class="p">{</span> <span class="s1">&#39;min_child_weight&#39;</span><span class="p">:[</span><span class="mi">2</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">15</span><span class="p">,</span><span class="mi">20</span><span class="p">,</span><span class="mi">25</span><span class="p">,</span><span class="mi">50</span><span class="p">,</span><span class="mi">75</span><span class="p">,</span><span class="mi">100</span><span class="p">,</span><span class="mi">200</span><span class="p">],</span>
          <span class="s1">&#39;max_depth&#39;</span> <span class="p">:</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">15</span><span class="p">,</span><span class="mi">20</span><span class="p">,</span><span class="mi">30</span><span class="p">],</span>
          <span class="s1">&#39;gamma&#39;</span><span class="p">:[</span><span class="mi">0</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">15</span><span class="p">,</span><span class="mi">20</span><span class="p">,</span><span class="mi">25</span><span class="p">,</span><span class="mi">30</span><span class="p">,</span><span class="mi">35</span><span class="p">,</span><span class="mi">100</span><span class="p">],</span>
          <span class="s1">&#39;n_estimators&#39;</span><span class="p">:[</span><span class="mi">5</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">15</span><span class="p">,</span><span class="mi">20</span><span class="p">,</span><span class="mi">30</span><span class="p">,</span><span class="mi">40</span><span class="p">,</span><span class="mi">50</span><span class="p">,</span><span class="mi">100</span><span class="p">,</span><span class="mi">500</span><span class="p">,</span><span class="mi">1000</span><span class="p">]}</span>
</pre></div>
</div>
<p>The first time I ran the grid search it took about 6 hours so I
subsequently reduced the number of <em>early stopping rounds</em> to 5 to speed
things up which substaintially reduced running time. While working on
this dataset for my early post, I noticed that once the AUC stopped
moving, it didn’t improve again later so I was quite happy to set it so
low. I also only tested the defualt 10 randomly chosen candidates before
the neighbourhood search and only used 2 cross-fold validations to
decrease the time taken.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">bestCandidate</span><span class="p">,</span> <span class="n">metric_bestCandidate</span> <span class="o">=</span> <span class="n">gridSearch</span><span class="p">(</span><span class="n">grid</span><span class="p">,</span>
                                                 <span class="n">df</span><span class="p">,</span>
                                                 <span class="n">target</span><span class="o">=</span><span class="s1">&#39;y&#39;</span><span class="p">,</span>
                                                 <span class="n">cv</span><span class="o">=</span><span class="mi">2</span>
                                                 <span class="n">balance</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                                 <span class="n">early_stopping_rounds</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;result bestCandidate&#39;</span><span class="p">,</span> <span class="n">bestCandidate</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;result metric_bestCandidate&#39;</span><span class="p">,</span> <span class="n">metric_bestCandidate</span><span class="p">)</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="../../_images/sortie_1.PNG"><img alt="../../_images/sortie_1.PNG" src="../../_images/sortie_1.PNG" style="width: 600px;" /></a>
<p>We can see that the intially identified ‘best candidate’ from the
initial 10 random candidates with a mean ROC AUC of 0.7237 is:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">params</span> <span class="o">=</span> <span class="p">{</span> <span class="s1">&#39;min_child_weight&#39;</span><span class="p">:</span><span class="mi">200</span><span class="p">,</span>
          <span class="s1">&#39;max_depth&#39;</span> <span class="p">:</span> <span class="mi">20</span><span class="p">,</span>
          <span class="s1">&#39;gamma&#39;</span><span class="p">:</span><span class="mi">5</span><span class="p">,</span>
          <span class="s1">&#39;n_estimators&#39;</span><span class="p">:</span><span class="mi">100</span><span class="p">}</span>
</pre></div>
</div>
<p>The neighbourhood of this best candidate is then tested to see if we can
improve the AUC. This resulted in an final choice of parameters with a
ROC AUC of 0.7270 as per below:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">params</span> <span class="o">=</span> <span class="p">{</span> <span class="s1">&#39;min_child_weight&#39;</span><span class="p">:</span><span class="mi">200</span><span class="p">,</span>
          <span class="s1">&#39;max_depth&#39;</span> <span class="p">:</span> <span class="mi">20</span><span class="p">,</span>
          <span class="s1">&#39;gamma&#39;</span><span class="p">:</span><span class="mi">10</span><span class="p">,</span>
          <span class="s1">&#39;n_estimators&#39;</span><span class="p">:</span><span class="mi">100</span><span class="p">}</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="../../_images/sortie_best.PNG"><img alt="../../_images/sortie_best.PNG" src="../../_images/sortie_best.PNG" style="width: 600px;" /></a>
<p>This final result wasn’t really worth the extra time and effort
especially when compared to the second run which result in a ROC AUC of
0.7615 for the below parameters:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">params</span> <span class="o">=</span> <span class="p">{</span> <span class="s1">&#39;min_child_weight&#39;</span><span class="p">:</span><span class="mi">2</span><span class="p">,</span>
          <span class="s1">&#39;max_depth&#39;</span> <span class="p">:</span> <span class="mi">15</span><span class="p">,</span>
          <span class="s1">&#39;gamma&#39;</span><span class="p">:</span><span class="mi">30</span><span class="p">,</span>
          <span class="s1">&#39;n_estimators&#39;</span><span class="p">:</span><span class="mi">50</span><span class="p">}</span>
</pre></div>
</div>
<p>We see quite clearly the impact of the starting point for the
neighbourhood search - choosing 10 random test candidates was probably
not enough. However, this can still give an idea of the impact of
changing any single parameter. For example, in some initial testing I
did, I noticed that an increase in gamma had a noticeable impact on the
AUC which would indicate it could be worth testing a grid including
another higher value of gamma. Another possible improvement is
restarting the neighbourhood search each time a new <em>best candidate</em> is
identified within a given neighbourhood search.</p>
</section>

<div class="section">
    

<div class="section">
  <span style="float: left">
     Previous:
    
    <a href="../xgboost/">
       XGBoost
    </a>
    
  </span>
  <span>&nbsp;</span>
  <span style="float: right">
     Next: 
    <a href="../memoryCraft/">
      Memory Craft 
    </a>
    
  </span>
</div>
  
</div>

          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../../"></a></h1>








  
<h2>
   
  26 May 2019 
</h2>

<ul>
   
<li id="author">
  <span
    >Author:</span
  >
   
  <a href="../../blog/author/keri-sime/">Keri Sime</a>  
</li>
     
</ul>

<h3>
  <a href="../../blog/">Recent Posts</a>
</h3>
<ul>
   
  <li>
    <a href="../spatialDemo/"
      >25 April - Spatial Demo</a
    >
  </li>
  
  <li>
    <a href="../scrapeDynamic/"
      >10 December - Scrape a Dynamic Website</a
    >
  </li>
  
  <li>
    <a href="../scrapeAndSend/"
      >02 October - Scrape and Send</a
    >
  </li>
  
  <li>
    <a href="../shipSchedule/"
      >15 June - Scheduling Ships</a
    >
  </li>
  
  <li>
    <a href="../projMgmnt/"
      >15 April - Managing a Machine Learning Project</a
    >
  </li>
  
</ul>

<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../search/" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>document.getElementById('searchbox').style.display = "block"</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2022, Keri Sime.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 5.0.1</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="../../_sources/posts/searchGrid.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>